{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import coremltools as ct\n",
    "\n",
    "from alphapose.utils.config import update_config\n",
    "from alphapose.models import builder\n",
    "\n",
    "\n",
    "cfg_path = \"./configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml\"\n",
    "cfg = update_config(cfg_path)\n",
    "\n",
    "# model_path = \"./exp/delme4-256x192_res50_lr1e-3_1x.yaml/model_7.pth\"\n",
    "model_path = \"./pretrained_models/fast_res50_256x192.pth\"\n",
    "\n",
    "model = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)\n",
    "model.load_state_dict(torch.load(model_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace with random data\n",
    "random_input = torch.rand(1, 3, 256, 192) # after test, will get 'size mismatch' error message with size 256x256\n",
    "traced_model = torch.jit.trace(model, random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch 1.6.0\n",
    "# Convert to Core ML using the Unified Conversion API\n",
    "model = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[ct.ImageType(name=\"input_1\", shape=random_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PIL to load and resize the image to expected size\n",
    "from PIL import Image\n",
    "example_image = Image.open(\"test_img.png\")\n",
    "print(example_image.size)\n",
    "\n",
    "\n",
    "# Make a prediction using Core ML\n",
    "out_dict = model.predict({\"input_1\": example_image})\n",
    "\n",
    "# Print out top-1 prediction\n",
    "print(out_dict[\"classLabel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-excellence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
